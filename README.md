# ğŸ Lexical Analyzer (Lexer) Project ğŸ”

Uma ferramenta educativa para analisar cÃ³digo C e transformÃ¡-lo em **tokens**! ğŸ’»âœ¨

---

## ğŸ‡§ğŸ‡· PortuguÃªs

### âœ¨ VisÃ£o Geral do Projeto
Este Ã© um **Analisador LÃ©xico (Lexer)** simples, desenvolvido em **Python ğŸ** com interface grÃ¡fica usando **Tkinter**.  
Ele atua como a primeira etapa de um compilador, lendo cÃ³digo-fonte C (`.c`) e transformando-o em uma lista estruturada de **Tokens**.

### ğŸ› ï¸ Componentes Principais

| Componente | FunÃ§Ã£o | Emoji |
|------------|--------|-------|
| `token_specs` | Define todas as regras (Regex) e seus rÃ³tulos (`NUM_INT`, `PLUS`, etc.) | ğŸ·ï¸ |
| `master_regex` | Super-regra compilada que varre o cÃ³digo de forma eficiente | ğŸš€ |
| `lexer(code)` | FunÃ§Ã£o central que reconhece, processa e descarta caracteres (como `SKIP`) | ğŸ§  |
| `LexicalAnalyzerApp` | Interface grÃ¡fica (GUI) para carregar arquivos e exibir o resultado | ğŸ–¥ï¸ |

### â–¶ï¸ Como Executar

**Requisitos:**  
- Python 3.x  
- Tkinter instalado

**ExecuÃ§Ã£o:**  

python seu_analisador.py
AnÃ¡lise:

Clique em "Abrir Arquivo .c"

Selecione o arquivo desejado

Clique em "Iniciar AnÃ¡lise LÃ©xica" para ver os tokens na caixa de texto

ğŸ§© Tokens Reconhecidos
Tipos e Palavras-chave: INT, IF, WHILE

Dados: NUM_INT, NUM_FLOAT

Estrutura: ASSIGN (=), PLUS (+), SEMI (;), LPAREN (() )

Tratamento de Erros: qualquer caractere nÃ£o reconhecido gera MISMATCH



ğŸ‡ºğŸ‡¸ English
âœ¨ Project Overview
This is a simple Lexical Analyzer (Lexer) built in Python ğŸ with a Tkinter GUI.
It works as the first stage of a compiler, reading C source code (.c) and converting it into a structured list of Tokens.

ğŸ› ï¸ Core Components
Component	Function	Emoji
token_specs	Defines all rules (Regex) and labels (NUM_INT, PLUS, etc.)	ğŸ·ï¸
master_regex	Compiled super-rule that efficiently scans the code	ğŸš€
lexer(code)	Core function that recognizes, processes, and discards characters (like SKIP)	ğŸ§ 
LexicalAnalyzerApp	GUI to load files and display output	ğŸ–¥ï¸

â–¶ï¸ How to Run
Requirements:

Python 3.x

Tkinter installed

Execution:

python your_analyzer.py
Analysis:

Click "Open .c File"

Select a file

Click "Start Lexical Analysis" to see the tokens in the text box

ğŸ§© Recognized Tokens
Types and Keywords: INT, IF, WHILE

Data: NUM_INT, NUM_FLOAT

Structure: ASSIGN (=), PLUS (+), SEMI (;), LPAREN (() )

Error Handling: any unrecognized character triggers a MISMATCH

ğŸ‡©ğŸ‡ª Deutsch
âœ¨ ProjektÃ¼bersicht
Dies ist ein einfacher Lexikalischer Analysator (Lexer) in Python ğŸ mit einer Tkinter-GUI.
Er fungiert als erste Stufe eines Compilers, liest C-Quellcode (.c) und wandelt ihn in eine strukturierte Liste von Tokens um.

ğŸ› ï¸ Hauptkomponenten
Komponente	Funktion	Emoji
token_specs	Definiert alle Regeln (Regex) und Labels (GANZE_ZAHL, PLUS, etc.)	ğŸ·ï¸
master_regex	Kompilierte Super-Regel, die den Code effizient scannt	ğŸš€
lexer(code)	Kernfunktion, die Zeichen erkennt, verarbeitet und verwirft (wie UEBERSPRINGEN)	ğŸ§ 
LexicalAnalyzerApp	GUI zum Laden von Dateien und Anzeigen der Ausgabe	ğŸ–¥ï¸

â–¶ï¸ AusfÃ¼hrung
Voraussetzungen:

Python 3.x

Tkinter installiert

AusfÃ¼hrung:


python ihr_analysator.py
Analyse:

Klicken Sie auf "C-Datei Ã¶ffnen"

Datei auswÃ¤hlen

Klicken Sie auf "Lexikalische Analyse starten", um die Tokens im Textfeld zu sehen

ğŸ§© Erkannte Tokens
Typen und SchlÃ¼sselwÃ¶rter: INT, IF, WHILE

Daten: GANZE_ZAHL, GLEITKOMMA_ZAHL

Struktur: ZUWEISUNG (=), PLUS (+), SEMICOLON (;), LINKSPARENTHESE (() )

Fehlerbehandlung: jedes nicht erkannte Zeichen lÃ¶st eine FEHLANPASSUNG aus